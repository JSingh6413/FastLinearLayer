{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using {} device'.format(device))\n",
    "\n",
    "\n",
    "from utils import show_images\n",
    "from models import MultilayerPerceptron\n",
    "from models import MLPMixer # need to install <einops>\n",
    "\n",
    "from layers import CustomLinear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'FashionMNISH'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root, \n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=2048, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=2048, shuffle=True)\n",
    "\n",
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "\n",
    "\n",
    "N_samples = 9\n",
    "images, labels = next(iter(train_dataloader))\n",
    "show_images(images[:N_samples], [labels_map[i.item()] for i in labels[:N_samples]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "from math import ceil\n",
    "from time import time\n",
    "\n",
    "\n",
    "def train_loop(model, dataloader, loss_fn, optimizer, step=0.05):\n",
    "    out = display(IPython.display.Pretty('Learning...'), display_id=True)\n",
    "\n",
    "    size = len(dataloader.dataset) \n",
    "    len_size = len(str(size))\n",
    "    batches = ceil(size / dataloader.batch_size) - 1\n",
    "    \n",
    "    percentage = 0\n",
    "    \n",
    "    history = {\n",
    "        'backward_time': []\n",
    "    }\n",
    "    for batch, (X, y) in enumerate(tqdm(dataloader, leave=False, desc=\"Batch #\")):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # evaluate\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        start = time()\n",
    "        loss.backward()\n",
    "        history['backward_time'].append(time() - start)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print info\n",
    "        if batch / batches > percentage or batch == batches: \n",
    "            out.update(f'[{int(percentage * size)}/{size}] Loss: {loss:>8f}')\n",
    "            percentage += step\n",
    "            \n",
    "    return history\n",
    "        \n",
    "        \n",
    "def test_loop(model, dataloader, loss_fn):\n",
    "\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "    batches = ceil(size / dataloader.batch_size)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, y) in enumerate(tqdm(dataloader, leave=False, desc='Batch #')):\n",
    "            \n",
    "            X, y = X.to(device), y.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(dim=1) == y).type(torch.int).sum().item()\n",
    "\n",
    "    test_loss /= batches\n",
    "    correct /= size\n",
    "    \n",
    "    print(f\"Validation accuracy: {(100*correct):>0.1f}%, Validation loss: {test_loss:>8f} \\n\")\n",
    "    return 100 * correct, test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load mixer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uncomment this to start the memory test. ( ~7 Gb VideoRAM instead of 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# batch_size = 510\n",
    "\n",
    "# train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "# test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# net = MLPMixer(\n",
    "#     image_size=28, channels=1, patch_size=4, \n",
    "#     dim=256, depth=15, \n",
    "#     num_classes=10, \n",
    "#     Dense=CustomLinear(100, 'naive')\n",
    "# ).to(device)\n",
    "\n",
    "# loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "# optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "# for epoch in range(1):\n",
    "#     print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "#     train_loop(net, train_dataloader, loss_fn, optimizer)\n",
    "#     test_loop(net, test_dataloader, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Number of parameters:', sum(p.numel() for p in net.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks = [256, 512, 512, 256]\n",
    "epochs = 8\n",
    "in_features = images[0].shape\n",
    "out_features = 10\n",
    "k = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy, Loss and Time per Batch tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "history = {\n",
    "    'torch': None,\n",
    "    'naive': None,\n",
    "    'vanilla': None,\n",
    "    'gauss': None,\n",
    "}\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=2048, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=2048, shuffle=True)\n",
    "\n",
    "for method in history.keys():\n",
    "    \n",
    "    print(f'METHOD: {method}')\n",
    "    \n",
    "    net = MultilayerPerceptron(in_features, out_features, blocks, CustomLinear(k, method)).to(device)\n",
    "\n",
    "    loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "    backward_time = []\n",
    "    accuracy = []\n",
    "    loss = []\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "        backward_time.append(train_loop(net, train_dataloader, loss_fn, optimizer)['backward_time'])\n",
    "        val_acc, val_loss = test_loop(net, test_dataloader, loss_fn)\n",
    "        accuracy.append(val_acc)\n",
    "        loss.append(val_loss)\n",
    "        \n",
    "    history[method] = (backward_time, accuracy, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "for method, (backward_time, accuracy, loss) in history.items():\n",
    "    \n",
    "    plt.plot(np.arange(len(loss)), loss, label=method)\n",
    "    \n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Loss on validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "for method, (backward_time, accuracy, loss) in history.items():\n",
    "    \n",
    "    plt.plot(np.arange(len(accuracy)), accuracy, label=method)\n",
    "    \n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('Accuracy on validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution time over batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "batch_sizes = [64, 128, 256, 512, 1024, 2048, 4096]\n",
    "\n",
    "history = {\n",
    "    'torch': {},\n",
    "    'naive': {},\n",
    "    'vanilla': {},\n",
    "    'gauss': {},\n",
    "}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    \n",
    "    print(f'BATCH SIZE: {batch_size}')\n",
    "    \n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for method in history.keys():\n",
    "\n",
    "        print(f'METHOD: {method}')\n",
    "\n",
    "        net = MultilayerPerceptron(in_features, out_features, blocks, CustomLinear(k, method))\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "        backward_time = train_loop(net, train_dataloader, loss_fn, optimizer)['backward_time']\n",
    "        history[method][batch_size] = backward_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "for method, backward_time in history.items():\n",
    "    \n",
    "    batch_sizes = backward_time.keys()\n",
    "    timings = [np.mean(backward_time[batch_size]) for batch_size in batch_sizes]\n",
    "\n",
    "    plt.plot(batch_sizes, timings, label=method)\n",
    "    \n",
    "plt.xscale('log', base=2)\n",
    "plt.xlabel('Batch size')\n",
    "plt.ylabel('Average time, s')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy after 2 epochs over different factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "factors = [20, 50, 100, 200, 300, 400, 600, 1000]\n",
    "\n",
    "history = {\n",
    "    'torch': {},\n",
    "    'naive': {},\n",
    "    'vanilla': {},\n",
    "    'gauss': {},\n",
    "}\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=2048, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=2048, shuffle=True)\n",
    "\n",
    "for factor in factors:\n",
    "    \n",
    "    print(f'FACTOR: {factor}')\n",
    "    \n",
    "\n",
    "    for method in history.keys():\n",
    "\n",
    "        print(f'METHOD: {method}')\n",
    "\n",
    "        net = MultilayerPerceptron(in_features, out_features, blocks, CustomLinear(factor, method))\n",
    "\n",
    "        loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "        optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "        train_loop(net, train_dataloader, loss_fn, optimizer)['backward_time']\n",
    "        acc, loss = test_loop(net, train_dataloader, loss_fn)\n",
    "        history[method][factor] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "for method, accuracy in history.items():\n",
    "    \n",
    "    factors = accuracy.keys()\n",
    "    accuracy = [np.mean(accuracy[factor]) for factor in factors]\n",
    "\n",
    "    plt.plot(factors, accuracy, label=method)\n",
    "    \n",
    "plt.xlabel('Factor, $r$')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
